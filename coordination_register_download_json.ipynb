{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Downloading the full dataset as a JSON-file\n",
    "This alternative gives you the data in the same JSON-structure as you get from the API (except the \"navigation\"-metadata about pages etc that is not relevant when you have all the data), and you can reuse the code you use for the search API, as well as quite easy keep a local copy in sync with the update-API.\n",
    "\n",
    "Pros:\n",
    "- Some types are correctly interpreted, for instance boolean values, as they use JSON \"true/false\"-values\n",
    "- easy to integrate with other applications as JSON has very good support in all programming languages\n",
    "\n",
    "Cons:\n",
    "- When read "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "source": [
    "Download and save to a file in the working directory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.brreg.no/enhetsregisteret/api/enheter/lastned'\n",
    "headers = {'Accept': 'application/vnd.brreg.enhetsregisteret.enhet.v1+gzip;charset=UTF-8'}\n",
    "session = requests.Session() # establish a session that is kept open during the transfer, instead of performing separate requests\n",
    "r = session.get(url, headers=headers, stream = True)\n",
    "r.raise_for_status()\n",
    "with open('er.json.gz','wb') as f:\n",
    "    for chunk in r.iter_content(1024*1024*10):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}